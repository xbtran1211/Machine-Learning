{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Randomly select 3 classes with 100 images per class for this assignment.\n",
    "2. Build the autoencoder model using CNN with functioning training code (if not CNN based, 60% reduction of marks will incur for this task).\n",
    "3. Plot the learnt images 2D coordinates (normally called embeddings in machine learning) of all images in training with each class denoted b a symbol, for example, circles for dogs, triangles for cats and so on.\n",
    "4. Randomly select 5 images that are not in the training set and obtain their 2D representations, add them to the plot produced in task 3 and describe what do you.\n",
    "think about them in terms of their locations in relations to others. Your code should produce the plot similar to Fig 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a supervised manifold learning model on CIFAR-10 images. The main idea is to incorporate labels information in the manifold learning process. It is very similar to LDA (linear discriminant analysis) in terms of functionality. However, instead of a lienar function, we use neural networks autoencoder as the backbone for manifold learning. Therefore, the model is a combination of autoencoder and classification, i.e. incorporating supervision information inthe modelling process, for exmaple, addding classification cost function into original autoencoder cost function. Do task 1-4 (see above) but replace the autoencoder by this supervised one.\n",
    "\n",
    "**NOTE: this is extra 10 marks contributing towards your final scores if you can do it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORKING SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and packages that will be used throughout the assignment\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import os\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Random split modules \n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load and normalise CIFAR10\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "\n",
    "#neural network training\n",
    "from torch import nn\n",
    "from torch.nn import ConvTranspose2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download and load the image dataset from CIFAR10 packages\n",
    "torch.manual_seed(0)\n",
    "CIF_dataset = CIFAR10(os.getcwd(), transform = transforms.ToTensor(), download = True) # CIFAR dataset\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 7]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly choose 3 classes from this dataset for future analysis\n",
    "random.seed(3)\n",
    "random.sample(range(0,9),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the selected random classes: 3, 2, and 7. The classes will be assigned for bird, automobile, and frog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From CIFAR-10 dataset, we select 100 images for each of the 3 classes:\n",
    "row_1 = list(np.where(np.array(CIF_dataset.targets) == 3)[0])[0:100]\n",
    "row_2 = list(np.where(np.array(CIF_dataset.targets) == 2)[0])[0:100]\n",
    "row_3 = list(np.where(np.array(CIF_dataset.targets) == 7)[0])[0:100]\n",
    "row_binded = row_1 + row_2 + row_3\n",
    "\n",
    "for i in range(10):\n",
    "    random.Random(i).shuffle(row_binded) #shuffle 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use subset to bind rows that matched:\n",
    "CIF_dataset1 = torch.utils.data.Subset(CIF_dataset, row_binded)\n",
    "len(CIF_dataset) # 300 images for 3 classes (100 images per class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sets for training, valdating and testing\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(CIF_dataset1, [100,100,100])\n",
    "\n",
    "# Load data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 5, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size = 5, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 5, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create an Convolutional Neural Network AutoEncoder having the bottleneck layer output as 2 units.\n",
    "\n",
    "Based on some researched information, the layer size can be determined as follows:\n",
    "\n",
    "- CONVOLUTIONAL LAYER : (W - F + 2P)/S + 1\n",
    "- TRANSPOSED CONVOLUTIONAL LAYER: (W - 1) * S - 2P + F\n",
    "- W = input size (default = 0)\n",
    "- F = kernel_size (default = 0)\n",
    "- P = padding (default = 0)\n",
    "- S = stride (default = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN AUTOENCODER\n",
    "class CNNAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # N, 3, 32 * 32 size\n",
    "        self.encoder_layer = nn.Sequential(\n",
    "            # Conv_layer block 1\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 5, padding = 2), # 32 x 32 x 32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace = True),\n",
    "\n",
    "            # Conv_layer block 2\n",
    "            nn.Conv2d(in_channels = 32, out_channels = 16, kernel_size = 3, padding = 1), # 16 x 32 x 32\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2), # 16 x 16 x 16\n",
    "            \n",
    "            # Conv_layer block 3\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 5, padding = 2), # 16 x 16 x 16\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2), # 16 x 8 x 8\n",
    "\n",
    "            # Conv_layer block 4\n",
    "            nn.Conv2d(in_channels = 16, out_channels = 8, kernel_size = 3, padding = 1), # 8 x 8 x 8\n",
    "            nn.ReLU(inplace = True),\n",
    "            )\n",
    "        \n",
    "        self.bottle_neck = nn.Sequential(\n",
    "            nn.Linear(8 * 8 * 8, 2) # there are 2 units as output\n",
    "            )\n",
    "    \n",
    "        self.decoder_layer = nn.Sequential(\n",
    "            # Deconv_layer block 1\n",
    "            nn.ConvTranspose2d(in_channels = 8, out_channels = 16, kernel_size = 2, stride = 2), # 16 x 16 x 16\n",
    "            nn.ReLU(inplace = True),\n",
    "\n",
    "            # Deconv_Layer block 2\n",
    "            nn.ConvTranspose2d(in_channels = 16, out_channels = 32, kernel_size = 2, stride = 2), # 32 x 32 x 32\n",
    "            nn.ReLU(inplace = True),\n",
    "\n",
    "            # Deconv_Layer block 3\n",
    "            nn.ConvTranspose2d(in_channels = 32, out_channels = 3, kernel_size = 3, padding = 1), # 3 x 32 x 32 #the output is the same as the input\n",
    "            nn.ReLU(inplace = True)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoder_layer\n",
    "        encoder_val = self.encoder_layer(x)\n",
    "\n",
    "        # bottleneck_layer\n",
    "        bottle_neck = encoder_val.view(encoder_val.size(0), - 1) # in terms of dimensionality, we fix it to be 2\n",
    "        bottle_neck = self.bottle_neck(bottle_neck)\n",
    "\n",
    "        # decoder_layer\n",
    "        x = self.decoder_layer(encoder_val)\n",
    "\n",
    "        return bottle_neck, x\n",
    "    \n",
    "model = CNNAutoEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we move onto creating a function to help train the CNN AutoEncoder model declared above, the required values to be inserted into the function will mainly consist of:\n",
    "- Optimiser\n",
    "- Chosen model\n",
    "- Loss function\n",
    "- Train dataloader\n",
    "- Validation dataloader\n",
    "- Number of epochs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def AutoEncoder_model_training(optimiser, model,\n",
    "                               Loss_function,\n",
    "                               trainloader, \n",
    "                               valloader,\n",
    "                               n_epochs = 10, fplotloss = True, #fdraw = False,\n",
    "                               filename = ''):\n",
    "    train_on_gpu = torch.cuda.is_available()\n",
    "    if train_on_gpu:\n",
    "        print(\"GPU available! Train model on GPU.\")\n",
    "        model.cuda()\n",
    "\n",
    "    # tracking\n",
    "    train_LossList = []\n",
    "    val_LossList = []\n",
    "\n",
    "    val_Loss_Min = np.Inf\n",
    "\n",
    "    # Entering Training Cycles\n",
    "    print(\"Entering training cycles with CNN AutoEncoder\")\n",
    "    for epoch in [*range(n_epochs)]:\n",
    "\n",
    "        # keeping tacking of training loss and validation loss\n",
    "        train_Loss = 0.0\n",
    "        val_Loss = 0.0\n",
    "\n",
    "        # for train model\n",
    "        model.train()\n",
    "        for data, target in trainloader:\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # clear gradient of all optimised variables\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            #f orward pass: predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "\n",
    "            # batch loss:\n",
    "            Batch_Loss = Loss_function(output[1], data)\n",
    "\n",
    "            # backward pass: compute gradients of the loss with respect to model parameters\n",
    "            Batch_Loss.backward()\n",
    "\n",
    "            # optimisation step (parameter update)\n",
    "            optimiser.step()\n",
    "\n",
    "            # update training Loss\n",
    "            train_Loss += Batch_Loss.item() * data.size(0)\n",
    "\n",
    "        # validate the model\n",
    "        model.eval()\n",
    "        for data, target in valloader:\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # forward pass: predicts outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "\n",
    "            # batch_loss:\n",
    "            Batch_Loss = Loss_function(output[1], data)\n",
    "\n",
    "            # Update validation loss:\n",
    "            val_Loss += Batch_Loss.item() * data.size(0)\n",
    "\n",
    "        # Calculate avg losses\n",
    "        train_Loss = train_Loss / len(trainloader.dataset)\n",
    "        val_Loss = val_Loss / len(valloader.dataset)\n",
    "\n",
    "        # append the Loss values to the Loss lists declared\n",
    "        train_LossList.append(train_Loss)\n",
    "        val_LossList.append(val_Loss)\n",
    "\n",
    "        # print the statistics\n",
    "        print('Epoch: {} \\tTraining_Loss: {:.6f} \\t Validation_Loss: {:.6f}'.format(epoch, train_Loss, val_Loss))\n",
    "\n",
    "        # if validation loss decreased\n",
    "        if val_Loss <= val_Loss_Min: # print if val loss decreased\n",
    "            print('Validation Loss decreased: ({:.6f} --> {:.6f}). Saving.'.format(val_Loss_Min, val_Loss))\n",
    "            torch.save(model.state_dict(), 'bestCNNAutoEncoder_model' + filename + '.pt') # we then proceed onto saving the best model\n",
    "            val_Loss_Min = val_Loss\n",
    "\n",
    "    # Plot Training and Validation Loss if fplotloss = True\n",
    "    if fplotloss == True:\n",
    "        plt.plot(*range(n_epochs), train_LossList)\n",
    "        plt.plot(*range(n_epochs), val_LossList)\n",
    "        plt.ylim((min(train_LossList + val_LossList), max(train_LossList + val_LossList)))\n",
    "        plt.xlabel('Epoch_n:')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Model Performance')\n",
    "        plt.legend(['Training Loss', 'Validation Loss'])\n",
    "        plt.show()\n",
    "    # Cycles is complete\n",
    "    print('Training process is now completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering training cycles with CNN AutoEncoder\n",
      "Epoch: 0 \tTraining_Loss: 0.160544 \t Validation_Loss: 0.113857\n",
      "Validation Loss decreased: (inf --> 0.113857). Saving.\n",
      "Epoch: 1 \tTraining_Loss: 0.092058 \t Validation_Loss: 0.080645\n",
      "Validation Loss decreased: (0.113857 --> 0.080645). Saving.\n",
      "Epoch: 2 \tTraining_Loss: 0.070809 \t Validation_Loss: 0.070125\n",
      "Validation Loss decreased: (0.080645 --> 0.070125). Saving.\n",
      "Epoch: 3 \tTraining_Loss: 0.062926 \t Validation_Loss: 0.065880\n",
      "Validation Loss decreased: (0.070125 --> 0.065880). Saving.\n",
      "Epoch: 4 \tTraining_Loss: 0.059629 \t Validation_Loss: 0.064186\n",
      "Validation Loss decreased: (0.065880 --> 0.064186). Saving.\n",
      "Epoch: 5 \tTraining_Loss: 0.058197 \t Validation_Loss: 0.063428\n",
      "Validation Loss decreased: (0.064186 --> 0.063428). Saving.\n",
      "Epoch: 6 \tTraining_Loss: 0.057526 \t Validation_Loss: 0.063096\n",
      "Validation Loss decreased: (0.063428 --> 0.063096). Saving.\n",
      "Epoch: 7 \tTraining_Loss: 0.057216 \t Validation_Loss: 0.062932\n",
      "Validation Loss decreased: (0.063096 --> 0.062932). Saving.\n",
      "Epoch: 8 \tTraining_Loss: 0.057019 \t Validation_Loss: 0.062890\n",
      "Validation Loss decreased: (0.062932 --> 0.062890). Saving.\n",
      "Epoch: 9 \tTraining_Loss: 0.057000 \t Validation_Loss: 0.062845\n",
      "Validation Loss decreased: (0.062890 --> 0.062845). Saving.\n"
     ]
    }
   ],
   "source": [
    "# train the model to the best model\n",
    "model = CNNAutoEncoder()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr = 0.01) # We will use stochastic gradient descent as an optimiser for this model\n",
    "\n",
    "AutoEncoder_model_training(optimiser, model, \n",
    "                           nn.MSELoss(), #Mean Squared Error Loss\n",
    "                           train_loader, val_loader,\n",
    "                           n_epochs = 10, fplotloss= True, filename= '_ver1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to train the model.\n",
    "\n",
    "With this problem, we would want to train the model until it becomes the best model, so that we can use it to visualise the images from the bottleneck layer of the CNN AutoEncoder model above onto a 2D coordinate graph. We will train the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model to the best model\n",
    "# model = CNNAutoEncoder()\n",
    "# optimiser = torch.optim.SGD(model.parameters(), lr = 0.01) # We will use stochastic gradient descent as an optimiser for this model\n",
    "\n",
    "# AutoEncoder_model_training(optimiser, model, \n",
    "#                            nn.MSELoss(), #Mean Squared Error Loss\n",
    "#                            train_loader, val_loader,\n",
    "#                            n_epochs = 20, fplotloss= True, filename= '_ver1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering training cycles with CNN AutoEncoder\n",
      "Epoch: 0 \tTraining_Loss: 0.160544 \t Validation_Loss: 0.113857\n",
      "Validation Loss decreased: (inf --> 0.113857). Saving.\n",
      "Epoch: 1 \tTraining_Loss: 0.092058 \t Validation_Loss: 0.080645\n",
      "Validation Loss decreased: (0.113857 --> 0.080645). Saving.\n",
      "Epoch: 2 \tTraining_Loss: 0.070809 \t Validation_Loss: 0.070125\n",
      "Validation Loss decreased: (0.080645 --> 0.070125). Saving.\n",
      "Epoch: 3 \tTraining_Loss: 0.062926 \t Validation_Loss: 0.065880\n",
      "Validation Loss decreased: (0.070125 --> 0.065880). Saving.\n",
      "Epoch: 4 \tTraining_Loss: 0.059629 \t Validation_Loss: 0.064186\n",
      "Validation Loss decreased: (0.065880 --> 0.064186). Saving.\n",
      "Epoch: 5 \tTraining_Loss: 0.058197 \t Validation_Loss: 0.063428\n",
      "Validation Loss decreased: (0.064186 --> 0.063428). Saving.\n",
      "Epoch: 6 \tTraining_Loss: 0.057526 \t Validation_Loss: 0.063096\n",
      "Validation Loss decreased: (0.063428 --> 0.063096). Saving.\n",
      "Epoch: 7 \tTraining_Loss: 0.057216 \t Validation_Loss: 0.062932\n",
      "Validation Loss decreased: (0.063096 --> 0.062932). Saving.\n",
      "Epoch: 8 \tTraining_Loss: 0.057019 \t Validation_Loss: 0.062890\n",
      "Validation Loss decreased: (0.062932 --> 0.062890). Saving.\n",
      "Epoch: 9 \tTraining_Loss: 0.057000 \t Validation_Loss: 0.062845\n",
      "Validation Loss decreased: (0.062890 --> 0.062845). Saving.\n",
      "Epoch: 10 \tTraining_Loss: 0.056891 \t Validation_Loss: 0.062798\n",
      "Validation Loss decreased: (0.062845 --> 0.062798). Saving.\n",
      "Epoch: 11 \tTraining_Loss: 0.056896 \t Validation_Loss: 0.062811\n",
      "Epoch: 12 \tTraining_Loss: 0.056843 \t Validation_Loss: 0.062822\n",
      "Epoch: 13 \tTraining_Loss: 0.056830 \t Validation_Loss: 0.062822\n",
      "Epoch: 14 \tTraining_Loss: 0.056818 \t Validation_Loss: 0.062799\n",
      "Epoch: 15 \tTraining_Loss: 0.056825 \t Validation_Loss: 0.062778\n",
      "Validation Loss decreased: (0.062798 --> 0.062778). Saving.\n",
      "Epoch: 16 \tTraining_Loss: 0.056820 \t Validation_Loss: 0.062759\n",
      "Validation Loss decreased: (0.062778 --> 0.062759). Saving.\n",
      "Epoch: 17 \tTraining_Loss: 0.056779 \t Validation_Loss: 0.062750\n",
      "Validation Loss decreased: (0.062759 --> 0.062750). Saving.\n",
      "Epoch: 18 \tTraining_Loss: 0.056756 \t Validation_Loss: 0.062699\n",
      "Validation Loss decreased: (0.062750 --> 0.062699). Saving.\n",
      "Epoch: 19 \tTraining_Loss: 0.056783 \t Validation_Loss: 0.062744\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# train the model to the best model\n",
    "model = CNNAutoEncoder()\n",
    "optimiser = torch.optim.SGD(model.parameters(), lr = 0.01) # We will use stochastic gradient descent as an optimiser for this model\n",
    "\n",
    "try:\n",
    "    AutoEncoder_model_training(optimiser, model, \n",
    "                               nn.MSELoss(), #Mean Squared Error Loss\n",
    "                               train_loader, val_loader,\n",
    "                               n_epochs = 20, fplotloss= True, filename= '_ver1')\n",
    "except RuntimeError as e:\n",
    "    if 'out of memory' in str(e):\n",
    "        print('Out of memory error: {}'.format(e))\n",
    "    else:\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
